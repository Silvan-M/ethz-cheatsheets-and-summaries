\section{Grundbegriffe}
\subsection{Wahrscheinlichkeitsraum}
\begin{mainbox}{Axiome von Kolmogorov}
    Das Tuple $(\Omega, \A, \P)$ ist ein \textbf{Wahrscheinlichkeitsraum} mit 
    \begin{enumerate}[label=\Roman*.]
        \item \textbf{Grundraum} $\Omega$ mit $\Omega \neq \emptyset$, wobei $\omega \in \Omega$ ein Elementarereignis ist.
        \item \textbf{$\sigma$-Algebra} $\A \subseteq \Pset(\Omega)$ wobei gilt:
        \begin{enumerate}[label=\arabic*.]
            \item $\Omega \in \A$
            \item $A \in \A \implies A^\complement \in \A$
            \item $A_1,A_2,\dots \in \A \implies \bigcup_i A_i \in \A$
        \end{enumerate}
        \item \textbf{Wahrscheinlichkeitsmass} $\P$ auf $(\Omega, \A)$ ist eine Abbildung $\P: \A \mapsto [0,1]$, wobei gilt:
        \begin{enumerate}[label=\arabic*.]
            \item $\P(\Omega) = 1$
            \item $A_1, A_2, \dots \in \A, \forall i \neq j: A_i \cap A_j = \emptyset \\ \implies \P(\bigcup_i A_i) = \sum_{i= 1}^\infty \P(A_i)$
        \end{enumerate}
    \end{enumerate}
\end{mainbox}

\textbf{De-Morgan}
    
Sei $(A_i)_{i \geq 1}$ eine Folge von beliebigen Mengen. Dann gilt
    $$\left(\bigcup_{i = 1}^{\infty}A_i\right)^\complement = \bigcap_{i = 1}^{\infty} (A_i)^\complement$$


Daraus folgt
\begin{enumerate}[label=\arabic*.]
    \item $A_1,A_2, \dots \in \A \implies \bigcap_{i=1}^{\infty}A_i \in \A$
    \item $A,B \in \A \implies (A \cup B), (A \cap B) \in \A$
\end{enumerate}
und für $A, B \in \A$
\begin{enumerate}[label=\arabic*.]
    \item $\P(A^\complement) = 1 - \P(A)$
    \item $A \subseteq B \implies \P(A) \leq \P(B)$
    \item $\P(A \cup B) = \P(A)+\P(B)-\P(A \cap B)$
\end{enumerate}
Sei $A_1,A_2, \dots \in \A$, dann gilt:\\
\textbf{Union Bound}
    $$\P\left(\bigcup_{i=1}^{\infty} A_i \right) \leq \sum_{i=1}^{\infty}\P(A_i)$$
\textbf{Siebformel}
    $$\P\left[\bigcup_{i=1}^n A_i\right]=\sum_{k=1}^n(-1)^{k+1} \sum_{1 \leq i_1<\cdots<i_k \leq n} \P\left[\bigcap_{j=1}^k A_{i_j}\right]$$
Für $n=2$:    $\quad P[A \cup B]=P[A]+P[B]-P[A \cap B]$
\subsection{Bedingte Wahrscheinlichkeiten}
 Sei $(\Omega, \A, \P)$ ein Wahrscheinlichkeitsraum.
 \begin{mainbox}{Bedingte Wahrscheinlichkeit}
    Sei $A, B \in \A$ und $\P(B) > 0$, dann ist die \textbf{bedingte Wahrscheinlichkeit von $A$ gegeben $B$}
    $$\P(A\mid B) = \frac{\P(A \cap B)}{\P(B)}$$
 \end{mainbox}
\textbf{Satz der totalen Wahrscheinlichkeit}

Sei $B_1, \ldots, B_N$ mit $\mathbb{P}\left[B_n\right]>0$ für jedes $1 \leq n \leq N$ eine Partition des Grundraums $\Omega$, d.h. $\bigcup_{n=1}^N B_n=\Omega$ mit $B_n \cap B_m=\emptyset$ für $n \neq m$. Dann gilt für alle $A \in \mathcal{F}$,
$$\mathbb{P}[A]=\sum_{n=1}^N \mathbb{P}\left[A \mid B_n\right] \mathbb{P}\left[B_n\right]=\sum_{n=1}^N \mathbb{P}\left[A \cap B_n\right]$$
\textbf{Satz von Bayes}

Aus der Definition der bedingten W'keit folgt sofort die Bayessche Formel, welche den Zusammenhang zwischen $\P(A\mid B)$ und $\P(B\mid A)$ beschreibt:
$$\P(B\mid A) = \frac{\P(A\mid B)\P(B)}{\P(A)}$$
Mit dem \textit{Satz der totalen W'keit} erhalten wir:

Sei $B_1, \ldots, B_N \in \mathcal{F}$ eine \textbf{Partition} von $\Omega$ mit $\mathbb{P}\left[B_n\right]>0$ für alle $n$. Für jedes Ereignis $A$ mit $\mathbb{P}[A]>0$ und jedes $n \in\{1, \ldots, N\}$ gilt
$$\mathbb{P}\left[B_n \mid A\right]=\frac{\mathbb{P}\left[A \mid B_n\right] \mathbb{P}\left[B_n\right]}{\sum_{k=1}^N \mathbb{P}\left[A \mid B_k\right] \mathbb{P}\left[B_k\right]}$$

\textbf{Intuition Bayessche Statistik}

In dieser Form würde man $A$ als das \textbf{eingetretene Ereignis} und die $B_i$ als die verschiedene \textbf{Hypothesen} verstehen. 

In der Bayesschen Statistik versucht man die Hypothese zu finden, so dass $\P(B_i\mid A)$ \textbf{maximiert} wird.

(Wurde in der Vorlesung nicht weiter behandelt)
\subsection{Unabhängigkeit} 
\begin{mainbox}{}
    Zwei Ereignisse $A, B \in \A$ heissen \textbf{(stochastisch) unabhängig}, wenn 
    $$\P(A\cap B) = \P(A) \cdot \P(B)$$
\end{mainbox}
Es gilt ($\star$):
\begin{itemize}
    \item $\P(A) \in \{0, 1\} \implies A \text{ zu jedem Ereignis unabhängig}$
    \item $A$ zu sich selbst unabhängig $\implies \P(A) \in \{0,1\}$
    \item $A, B$ unabhängig $\implies$ $A, B^\complement$ unabhängig
\end{itemize}
Wenn $\P(A) > 0, \P(B) > 0$ gilt:\\
 $A,B$ unabh.$\iff$ $\P(A|B)=\P(A)$ $\iff$ $\P(B|A)=\P(B)$

\begin{mainbox}{}
    Eine Kollektion von Ereignissen $\left(A_i\right)_{i \in I}$ heisst \textbf{(stochastisch) unabhängig}, wenn 
    $$J \subseteq I \text{ endlich} \implies \P\left(\bigcap_{i\in J} A_i\right) = \prod_{i \in J} \P(A_i)$$
\end{mainbox}

