\section{Tests}
\begin{subbox}{}
	Die \tbf{Nullhypothese} \(H_0\) und die \tbf{Alternativhypothese} \(H_A\) sind zwei Teilmengen \(\Theta_0 \subseteq \Theta, \Theta_A \subseteq \Theta\) wobei \(\Theta_0 \cap \Theta_A = \varnothing\). 

	Falls keine explizite Alternativhypothese spezifiziert ist, so hat man $\Theta_A = \Theta \setminus \Theta_0$. 

	Eine Hypothese heisst \textit{einfach}, falls die Teilmenge aus einem einzelnen Wert besteht; sonst \textit{zusammengesetzt}.
\end{subbox}

\begin{mainbox}{Definition Test}
	Ein Test ist ein Paar $(T, K)$, wobei:
\begin{itemize}
    \item $T=t(X_1, \ldots, X_n)$ die Teststatistik ist, mit einer messbaren Funktion $t: \mathbb{R}^n \rightarrow \mathbb{R}$.
    \item $K \subseteq \mathbb{R}$ der kritische Bereich oder Verwerfungsbereich ist.
\end{itemize}
\end{mainbox}

Wir wollen nun anhand der Daten \((X_1(\omega), \ldots, X_n(\omega))\) entscheiden, ob die Nullhypothese akzeptiert oder verworfen wird. Zuerst berechnen wir die Teststatistik \(T(\omega) = t(X_1(\omega), \ldots, X_n(\omega))\) und gehen dann wie folgt vor:
\begin{itemize}
	\item Die Hypothese \(H_0\) wird \textit{verworfen}, falls \(T(\omega) \in K\).
	\item Die Hypothese \(H_0\) wird \textit{akzeptiert}, falls \(T(\omega) \notin K\).
\end{itemize}
\begin{subbox}{}
	Ein \tbf{Fehler 1. Art} ist, wenn \(H_0\) fälschlicherweise verworfen wird, obwohl sie richtig ist.
	\[\P_\theta(T \in K), \quad \theta \in \Theta_0\]
	\noindent Ein \tbf{Fehler 2. Art} ist, wenn \(H_0\) fälschlicherweise akzeptiert wird, obwohl sie falsch ist.
	\[\P_\theta(T\notin K) = 1 - \P_\theta(T \in K), \quad \theta \in \Theta_A\]
\end{subbox}
\textbf{Bemerkung: } Da $T$ eine ZV und somit bezüglich dem Mass $\P_\theta: \F \to [0,1]$ messbar ist, gilt $\{T \in K\} \in \F$ und somit ist $\P_\theta(T \in K)$ wohldefiniert. 
\subsection{Signifikanzniveau und Macht}
Ein Test hat Signifikanzniveau \(a \in [0,1]\) falls
\[\forall \theta \in \Theta_0 \quad \P_\theta(T \in K) \le a\]
Es ist meist unser primäres Ziel, die Fehler 1. Art zu minimieren.

Das sekundäre Ziel ist, Fehler 2. Art zu vermeiden. Hierfür definieren wir die Macht eines Tests als Funktion:
\[\beta : \Theta_A \mapsto [0,1], \quad \theta \mapsto \P_\theta(T \in K)\]
Zu beachten ist, dass eine kleine Wahrscheinlichkeit für einen Fehler 2. Art einem \textit{grossen} \(\beta\) entspricht.

\subsection{Konstruktion von Tests}
Wir nehmen an, dass \(X_1, \ldots, X_n\) diskret oder gemeinsam stetig unter \(\P_{\theta_0}\) und \(\P_{\theta_A}\) sind, wobei \(\Theta_0 \cap \Theta_A = \emptyset\) einfach sind (\(\theta_0 \in \Theta_0 \land \theta_A \in \Theta_A\)).

\noindent Der Likelihood-Quotient ist somit wohldefiniert:
\[R(x_1, \ldots, x_n) = \frac{L(x_1,\ldots, x_n;\theta_A)}{L(x_1, \ldots, x_n;\theta_0)}\]
(Falls \(L(x_1, \ldots, x_n; \theta_0) = 0\) setzen wir \(R(x_1, \ldots, x_n) = +\infty\).) 

Für zusammengesetzte $\Theta_0$ und $\Theta_A$ können wir den verallg. Likelihood-Quotient definieren:
\[R(x_1, ..., x_n) := \frac{\sup_{\theta \in \Theta_A}L(x_1, \dots, x_n; \theta)}{\sup_{\theta \in \Theta_0}L(x_1, \dots, x_n; \theta)}\]


Wenn \(R \gg 1\), so gilt \(H_A > H_0\) und analog \(R \ll 1 \implies H_A < H_0\).

\begin{subbox}{}
	Der \tbf{Likelihood-Quotient-Test (LQ-Test)} mit Parameter \(c \ge 0\) ist definiert durch:
	\[T = R(X_1, \ldots, X_n) \quad \text{und} \quad K = (c, \infty]\]
\end{subbox}
\textbf{Neyman-Pearson-Lemma}

Sei $\Theta_0=\{\vartheta_0\}$ und $\Theta_A=\{\vartheta_A\}$. Sei $(T, K)$ ein Likelihood-Quotienten-Test mit Parameter $c$ und Signifikanzniveau $\alpha^* := \mathbb{P}_{\vartheta_0}[T \in K]$. Ist $(T', K')$ ein anderer Test mit Signifikanzniveau $\alpha := \mathbb{P}_{\vartheta_0}[T' \in K'] \leq \alpha^*$, so gilt:
$$
\mathbb{P}_{\vartheta_A}[T' \in K'] \leq \mathbb{P}_{\vartheta_A}[T \in K].
$$
Das bedeutet, jeder andere Test mit kleinerem Signifikanzniveau hat auch geringere Macht bzw. eine größere Wahrscheinlichkeit für einen Fehler 2. Art.

\subsection{T-Test / Gauss Test}
	
Zuerst berechnen wir $T$:
$$
T = \frac{\bar{X}_n - \theta_0}{\sqrt{\sigma^2 / n}} \sim \mathcal{N}(0,1)
$$
mit dem erwartungstreuen Schätzer:
$$
\bar{X}_n = \frac{1}{n} \sum_{i=1}^n X_i
$$

Dann unterscheiden wir zwischen den folgenden Fällen:

\begin{enumerate}
    \item Einseitiger Test $H_A$: $\theta > \theta_0$
    \begin{itemize}
        \item Obere Grenze: \(c = \Phi^{-1}(1 - \alpha)\)
        \item Verwerfungsbereich: Verwerfe \(H_0\) falls \(T > c\)
    \end{itemize}
    
    \item Einseitiger Test $H_A$: $\theta < \theta_0$
    \begin{itemize}
        \item Untere Grenze: \(c = \Phi^{-1}(\alpha)\)
        \item Verwerfungsbereich: Verwerfe \(H_0\) falls \(T < c\)
    \end{itemize}
    
    \item Beidseitiger Test $H_A$: $\theta \neq \theta_0$
    \begin{itemize}
        \item Untere Grenze: \(c_1 = \Phi^{-1}(\alpha / 2)\)\\
            Obere Grenze: \(c_2 = \Phi^{-1}(1 - \alpha / 2)\)
        \item  Verwerfe \(H_0\) falls \(T < c_1\) oder \(T > c_2\)
    \end{itemize}
\end{enumerate}
\textit{Notiz: Restliche Tests nicht in Vorlesung behandelt. (für restliche Tests siehe Nicolas Wehrli's Cheat Sheet)}